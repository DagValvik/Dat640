{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ir_datasets\n",
    "# dataset = ir_datasets.load(\"msmarco-passage\")\n",
    "# for doc in dataset.docs_iter():\n",
    "#     doc # namedtuple<doc_id, text>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "from sentence_transformers import CrossEncoder\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'passage_index', '_type': '_doc', '_id': '1', '_version': 1, '_seq_no': 1, '_primary_term': 1, 'found': True, '_source': {'content': 'The Manhattan Project and its atomic bomb helped bring an end to World War II. Its legacy of peaceful uses of atomic energy continues to have an impact on history and science.'}}\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch()\n",
    "# es.info()\n",
    "INDEX_NAME = \"passage_index\"\n",
    "doc = es.get(index=INDEX_NAME, id=1)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>786436</td>\n",
       "      <td>what is prescribed to treat thyroid storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>Refer to the data. Diminishing returns begin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>786450</td>\n",
       "      <td>what is presentation software?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524308</td>\n",
       "      <td>treasury routing number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>game called poem who wrote what occasion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                                  1\n",
       "0  786436          what is prescribed to treat thyroid storm\n",
       "1       9   Refer to the data. Diminishing returns begin ...\n",
       "2  786450                     what is presentation software?\n",
       "3  524308                            treasury routing number\n",
       "4      33           game called poem who wrote what occasion"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_eval = pd.read_csv(\"data/queries/queries.eval.tsv\", sep='\\t', header=None)#, index_col=0)\n",
    "queries_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8841823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The presence of communication amid scientific ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Manhattan Project and its atomic bomb help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Essay on The Manhattan Project - The Manhattan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Manhattan Project was the name for a proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>versions of each volume as well as complementa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  0  The presence of communication amid scientific ...\n",
       "1  1  The Manhattan Project and its atomic bomb help...\n",
       "2  2  Essay on The Manhattan Project - The Manhattan...\n",
       "3  3  The Manhattan Project was the name for a proje...\n",
       "4  4  versions of each volume as well as complementa..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_df = pd.read_csv(\"data/collection/collection.tsv\", sep='\\t', header=None) #, index_col=0)\n",
    "print(len(collection_df))\n",
    "collection_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrelspath = \"data/queries/qrels.txt\"\n",
    "\n",
    "qrels_ids = set()\n",
    "with open(qrelspath, encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        l = line.split(' ')\n",
    "        qrels_ids.add(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def relevant_queries(queries, qrels):\n",
    "#     relevant_queries = []\n",
    "#     relevant_queries_id = []\n",
    "\n",
    "#     for idx, query in enumerate(queries):\n",
    "#         query_id = str(queries_id[idx])\n",
    "#         if query_id in qrels:\n",
    "#             relevant_queries.append(query)\n",
    "#             relevant_queries_id.append(query_id)\n",
    "\n",
    "#     return relevant_queries, relevant_queries_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "queriesToUse = {}\n",
    "for _, query in queries_eval.iterrows():\n",
    "    if str(query[0]) in qrels_ids:\n",
    "        queriesToUse[query[0]] = query[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-2-v2', max_length=512)\n",
    "\n",
    "# ranked = {}\n",
    "\n",
    "# # Rank the top 1000 passages for each query\n",
    "# for query_id, query_text in queriesToUse.items():\n",
    "#     # print(query_id, query_text)\n",
    "#     # break\n",
    "#     for _, doc in collection_df.iterrows():\n",
    "#         # print(doc[0], doc[1])\n",
    "#         # break\n",
    "#         doc_id = doc[0]\n",
    "#         doc_text = doc[1]\n",
    "#         score = model.predict([(query_text, doc_text)])[0]\n",
    "#         if query_id not in ranked:\n",
    "#             ranked[query_id] = []\n",
    "#         ranked[query_id].append((doc_id, score))\n",
    "#         break\n",
    "#     ranked[query_id] = sorted(ranked[query_id], key=lambda x: x[1], reverse=True)[:1000]\n",
    "#     break\n",
    "# print(ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\elasticsearch\\connection\\base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "query_topK = {}\n",
    "for query_id, query in queriesToUse.items():\n",
    "    # query = queries[idx]\n",
    "    res = es.search(index=INDEX_NAME, q=query, _source=False, size=5000, request_timeout=60)\n",
    "    top_k_scores = [hit[\"_id\"] for hit in res[\"hits\"][\"hits\"]]\n",
    "    query_topK[str(query_id)] = top_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\elasticsearch\\connection\\base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 2.33%\n",
      "Processed: 4.65%\n",
      "Processed: 6.98%\n",
      "Processed: 9.3%\n",
      "Processed: 11.63%\n",
      "Processed: 13.95%\n",
      "Processed: 16.28%\n",
      "Processed: 18.6%\n",
      "Processed: 20.93%\n",
      "Processed: 23.26%\n",
      "Processed: 25.58%\n",
      "Processed: 27.91%\n",
      "Processed: 30.23%\n",
      "Processed: 32.56%\n",
      "Processed: 34.88%\n",
      "Processed: 37.21%\n",
      "Processed: 39.53%\n",
      "Processed: 41.86%\n",
      "Processed: 44.19%\n",
      "Processed: 46.51%\n",
      "Processed: 48.84%\n",
      "Processed: 51.16%\n",
      "Processed: 53.49%\n",
      "Processed: 55.81%\n",
      "Processed: 58.14%\n",
      "Processed: 60.47%\n",
      "Processed: 62.79%\n",
      "Processed: 65.12%\n",
      "Processed: 67.44%\n",
      "Processed: 69.77%\n",
      "Processed: 72.09%\n",
      "Processed: 74.42%\n",
      "Processed: 76.74%\n",
      "Processed: 79.07%\n",
      "Processed: 81.4%\n",
      "Processed: 83.72%\n",
      "Processed: 86.05%\n",
      "Processed: 88.37%\n",
      "Processed: 90.7%\n",
      "Processed: 93.02%\n",
      "Processed: 95.35%\n",
      "Processed: 97.67%\n"
     ]
    }
   ],
   "source": [
    "model = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-2-v2', max_length=512)\n",
    "\n",
    "ranked = {}\n",
    "\n",
    "# Rank the top 5000 passages for each query\n",
    "for i, (query_id, doc_ids) in enumerate(query_topK.items()):\n",
    "    print(f\"Processed: {round(i/len(query_topK)*100,2)}%\")\n",
    "    # print(query_id, doc_ids)\n",
    "    # print(es.get(index=INDEX_NAME, id=doc_ids[0])[\"_source\"][\"content\"])\n",
    "    # print(queriesToUse[query_id])\n",
    "\n",
    "    l = [(queriesToUse[int(query_id)], es.get(index=INDEX_NAME, id=doc_id)[\"_source\"][\"content\"]) for doc_id in doc_ids]\n",
    "    score = model.predict(l)\n",
    "    # print(score)\n",
    "    # print(len(score))\n",
    "    d = dict(zip(doc_ids, score))\n",
    "    ranked[query_id] = [k for k in sorted(d, key=d.get, reverse=True)]\n",
    "#     break\n",
    "# print(ranked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk indexing\n",
    "qrelspath = \"data/qrels/qrels.txt\"\n",
    "\n",
    "qrels = {}\n",
    "with open(qrelspath, encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        l = line.split(' ')\n",
    "\n",
    "        qid = l[0]\n",
    "        pid = l[2]\n",
    "        relevance = int(l[3])\n",
    "\n",
    "        if relevance > 0:\n",
    "            if qid in qrels.keys():\n",
    "                qrels[qid].add(pid)\n",
    "            else:\n",
    "                qrels[qid] = set([pid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_precision(system_ranking, ground_truth) -> float:\n",
    "    vals = []\n",
    "    over = 1\n",
    "    for rank_idx, rank in enumerate(system_ranking):\n",
    "        under = rank_idx+1\n",
    "        if rank in ground_truth:\n",
    "            vals.append(over / under)\n",
    "            over += 1\n",
    "    AP = sum(vals) / len(ground_truth)\n",
    "\n",
    "    return AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09030257145979574"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_ranking = query_topK[\"527433\"] # List\n",
    "system_truth = qrels[\"527433\"] # Set\n",
    "score = get_average_precision(system_ranking, system_truth)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reciprocal_rank(system_ranking, ground_truth) -> float:\n",
    "    AP = 0\n",
    "    for rank_idx, rank in enumerate(system_ranking):\n",
    "        under = rank_idx+1\n",
    "        if rank in ground_truth:\n",
    "            AP = 1 / under\n",
    "            break\n",
    "    \n",
    "    return AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_ranking = query_topK[\"527433\"] # List\n",
    "system_truth = qrels[\"527433\"] # Set\n",
    "score = get_reciprocal_rank(system_ranking, system_truth)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_eval_measure(system_rankings, ground_truths, eval_function: Callable) -> float:\n",
    "    results = []\n",
    "    for query in system_rankings:\n",
    "        if query in ground_truths.keys():\n",
    "            results.append(eval_function(system_rankings[query], ground_truths[query]))\n",
    "        else:\n",
    "            continue\n",
    "            # results.append(0) -> ?\n",
    "    return sum(results) / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = get_mean_eval_measure(query_topK, qrels, get_average_precision)\n",
    "mrr = get_mean_eval_measure(query_topK, qrels, get_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From BM25\n",
    "map = 0.32872575816078825\n",
    "\n",
    "mrr = 0.7265016684853105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3324887414761848\n",
      "0.7265135518853889\n"
     ]
    }
   ],
   "source": [
    "print(map)\n",
    "print(mrr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
