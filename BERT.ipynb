{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ir_datasets\n",
    "# dataset = ir_datasets.load(\"msmarco-passage\")\n",
    "# for doc in dataset.docs_iter():\n",
    "#     doc # namedtuple<doc_id, text>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "from sentence_transformers import CrossEncoder\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "ConnectionError(<urllib3.connection.HTTPConnection object at 0x000001DE42CC1600>: Failed to establish a new connection: [WinError 10061] Kan ikke koble til fordi målmaskinen avslo tilkobling) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x000001DE42CC1600>: Failed to establish a new connection: [WinError 10061] Kan ikke koble til fordi målmaskinen avslo tilkobling)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dns_host, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[39mraise\u001b[39;00m socket\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mgetaddrinfo returns an empty list\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] Kan ikke koble til fordi målmaskinen avslo tilkobling",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elasticsearch\\connection\\http_urllib3.py:255\u001b[0m, in \u001b[0;36mUrllib3HttpConnection.perform_request\u001b[1;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[0;32m    253\u001b[0m     request_headers[\u001b[39m\"\u001b[39m\u001b[39mcontent-encoding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 255\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39murlopen(\n\u001b[0;32m    256\u001b[0m     method, url, body, retries\u001b[39m=\u001b[39mRetry(\u001b[39mFalse\u001b[39;00m), headers\u001b[39m=\u001b[39mrequest_headers, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw\n\u001b[0;32m    257\u001b[0m )\n\u001b[0;32m    258\u001b[0m response_headers \u001b[39m=\u001b[39m {\n\u001b[0;32m    259\u001b[0m     header\u001b[39m.\u001b[39mlower(): value \u001b[39mfor\u001b[39;00m header, value \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    260\u001b[0m }\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    789\u001b[0m )\n\u001b[0;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\util\\retry.py:525\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m error:\n\u001b[0;32m    524\u001b[0m     \u001b[39m# Disabled, indicate to re-raise the error.\u001b[39;00m\n\u001b[1;32m--> 525\u001b[0m     \u001b[39mraise\u001b[39;00m six\u001b[39m.\u001b[39;49mreraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[0;32m    527\u001b[0m total \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\packages\\six.py:770\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 770\u001b[0m     \u001b[39mraise\u001b[39;00m value\n\u001b[0;32m    771\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39mrequest(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    238\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 239\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\http\\client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1282\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\http\\client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1328\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\http\\client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1277\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\http\\client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1037\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m \n\u001b[0;32m   1041\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\http\\client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[1;32m--> 975\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m    976\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001DE42CC1600>: Failed to establish a new connection: [WinError 10061] Kan ikke koble til fordi målmaskinen avslo tilkobling",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dvalv\\Documents\\GitHub\\Dat640\\BERT.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dvalv/Documents/GitHub/Dat640/BERT.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# es.info()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dvalv/Documents/GitHub/Dat640/BERT.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m INDEX_NAME \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassage_index\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dvalv/Documents/GitHub/Dat640/BERT.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m doc \u001b[39m=\u001b[39m es\u001b[39m.\u001b[39;49mget(index\u001b[39m=\u001b[39;49mINDEX_NAME, \u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dvalv/Documents/GitHub/Dat640/BERT.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(doc)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elasticsearch\\client\\utils.py:347\u001b[0m, in \u001b[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[39mif\u001b[39;00m p \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    346\u001b[0m         params[p] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(p)\n\u001b[1;32m--> 347\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, params\u001b[39m=\u001b[39mparams, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elasticsearch\\client\\__init__.py:1050\u001b[0m, in \u001b[0;36mElasticsearch.get\u001b[1;34m(self, index, id, doc_type, params, headers)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[39mif\u001b[39;00m doc_type \u001b[39min\u001b[39;00m SKIP_IN_PATH:\n\u001b[0;32m   1048\u001b[0m     doc_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_doc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1050\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransport\u001b[39m.\u001b[39;49mperform_request(\n\u001b[0;32m   1051\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, _make_path(index, doc_type, \u001b[39mid\u001b[39;49m), params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders\n\u001b[0;32m   1052\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elasticsearch\\transport.py:417\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[1;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39m# Before we make the actual API call we verify the Elasticsearch instance.\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verified_elasticsearch \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 417\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_verify_elasticsearch(headers\u001b[39m=\u001b[39;49mheaders, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    419\u001b[0m \u001b[39m# If '_verified_elasticsearch' isn't 'True' then we raise an error.\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verified_elasticsearch \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elasticsearch\\transport.py:606\u001b[0m, in \u001b[0;36mTransport._do_verify_elasticsearch\u001b[1;34m(self, headers, timeout)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[39m# If we received a connection error and weren't successful\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[39m# anywhere then we re-raise the more appropriate error.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \u001b[39mif\u001b[39;00m error \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m info_response:\n\u001b[1;32m--> 606\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[0;32m    608\u001b[0m \u001b[39m# Check the information we got back from the index request.\u001b[39;00m\n\u001b[0;32m    609\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verified_elasticsearch \u001b[39m=\u001b[39m _ProductChecker\u001b[39m.\u001b[39mcheck_product(\n\u001b[0;32m    610\u001b[0m     info_headers, info_response\n\u001b[0;32m    611\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elasticsearch\\transport.py:569\u001b[0m, in \u001b[0;36mTransport._do_verify_elasticsearch\u001b[1;34m(self, headers, timeout)\u001b[0m\n\u001b[0;32m    566\u001b[0m attempted_conns\u001b[39m.\u001b[39mappend(conn)\n\u001b[0;32m    568\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 569\u001b[0m     _, info_headers, info_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mperform_request(\n\u001b[0;32m    570\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m, headers\u001b[39m=\u001b[39;49mheaders, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    571\u001b[0m     )\n\u001b[0;32m    573\u001b[0m     \u001b[39m# Lowercase all the header names for consistency in accessing them.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     info_headers \u001b[39m=\u001b[39m {\n\u001b[0;32m    575\u001b[0m         header\u001b[39m.\u001b[39mlower(): value \u001b[39mfor\u001b[39;00m header, value \u001b[39min\u001b[39;00m info_headers\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    576\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elasticsearch\\connection\\http_urllib3.py:280\u001b[0m, in \u001b[0;36mUrllib3HttpConnection.perform_request\u001b[1;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m    279\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectionTimeout(\u001b[39m\"\u001b[39m\u001b[39mTIMEOUT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(e), e)\n\u001b[1;32m--> 280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mN/A\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(e), e)\n\u001b[0;32m    282\u001b[0m \u001b[39m# raise warnings if any from the 'Warnings' header.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m warning_headers \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget_all(\u001b[39m\"\u001b[39m\u001b[39mwarning\u001b[39m\u001b[39m\"\u001b[39m, ())\n",
      "\u001b[1;31mConnectionError\u001b[0m: ConnectionError(<urllib3.connection.HTTPConnection object at 0x000001DE42CC1600>: Failed to establish a new connection: [WinError 10061] Kan ikke koble til fordi målmaskinen avslo tilkobling) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x000001DE42CC1600>: Failed to establish a new connection: [WinError 10061] Kan ikke koble til fordi målmaskinen avslo tilkobling)"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch()\n",
    "# es.info()\n",
    "INDEX_NAME = \"passage_index\"\n",
    "doc = es.get(index=INDEX_NAME, id=1)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>786436</td>\n",
       "      <td>what is prescribed to treat thyroid storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>Refer to the data. Diminishing returns begin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>786450</td>\n",
       "      <td>what is presentation software?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524308</td>\n",
       "      <td>treasury routing number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>game called poem who wrote what occasion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                                  1\n",
       "0  786436          what is prescribed to treat thyroid storm\n",
       "1       9   Refer to the data. Diminishing returns begin ...\n",
       "2  786450                     what is presentation software?\n",
       "3  524308                            treasury routing number\n",
       "4      33           game called poem who wrote what occasion"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_eval = pd.read_csv(\"data/queries/queries.eval.tsv\", sep='\\t', header=None)#, index_col=0)\n",
    "queries_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8841823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The presence of communication amid scientific ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Manhattan Project and its atomic bomb help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Essay on The Manhattan Project - The Manhattan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Manhattan Project was the name for a proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>versions of each volume as well as complementa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  0  The presence of communication amid scientific ...\n",
       "1  1  The Manhattan Project and its atomic bomb help...\n",
       "2  2  Essay on The Manhattan Project - The Manhattan...\n",
       "3  3  The Manhattan Project was the name for a proje...\n",
       "4  4  versions of each volume as well as complementa..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_df = pd.read_csv(\"data/collection/collection.tsv\", sep='\\t', header=None) #, index_col=0)\n",
    "print(len(collection_df))\n",
    "collection_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrelspath = \"data/queries/qrels.txt\"\n",
    "\n",
    "qrels_ids = set()\n",
    "with open(qrelspath, encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        l = line.split(' ')\n",
    "        qrels_ids.add(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def relevant_queries(queries, qrels):\n",
    "#     relevant_queries = []\n",
    "#     relevant_queries_id = []\n",
    "\n",
    "#     for idx, query in enumerate(queries):\n",
    "#         query_id = str(queries_id[idx])\n",
    "#         if query_id in qrels:\n",
    "#             relevant_queries.append(query)\n",
    "#             relevant_queries_id.append(query_id)\n",
    "\n",
    "#     return relevant_queries, relevant_queries_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "queriesToUse = {}\n",
    "for _, query in queries_eval.iterrows():\n",
    "    if str(query[0]) in qrels_ids:\n",
    "        queriesToUse[query[0]] = query[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-2-v2', max_length=512)\n",
    "\n",
    "# ranked = {}\n",
    "\n",
    "# # Rank the top 1000 passages for each query\n",
    "# for query_id, query_text in queriesToUse.items():\n",
    "#     # print(query_id, query_text)\n",
    "#     # break\n",
    "#     for _, doc in collection_df.iterrows():\n",
    "#         # print(doc[0], doc[1])\n",
    "#         # break\n",
    "#         doc_id = doc[0]\n",
    "#         doc_text = doc[1]\n",
    "#         score = model.predict([(query_text, doc_text)])[0]\n",
    "#         if query_id not in ranked:\n",
    "#             ranked[query_id] = []\n",
    "#         ranked[query_id].append((doc_id, score))\n",
    "#         break\n",
    "#     ranked[query_id] = sorted(ranked[query_id], key=lambda x: x[1], reverse=True)[:1000]\n",
    "#     break\n",
    "# print(ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\elasticsearch\\connection\\base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "query_topK = {}\n",
    "for query_id, query in queriesToUse.items():\n",
    "    # query = queries[idx]\n",
    "    res = es.search(index=INDEX_NAME, q=query, _source=False, size=5000, request_timeout=60)\n",
    "    top_k_scores = [hit[\"_id\"] for hit in res[\"hits\"][\"hits\"]]\n",
    "    query_topK[str(query_id)] = top_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\elasticsearch\\connection\\base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 2.33%\n",
      "Processed: 4.65%\n",
      "Processed: 6.98%\n",
      "Processed: 9.3%\n",
      "Processed: 11.63%\n",
      "Processed: 13.95%\n",
      "Processed: 16.28%\n",
      "Processed: 18.6%\n",
      "Processed: 20.93%\n",
      "Processed: 23.26%\n",
      "Processed: 25.58%\n",
      "Processed: 27.91%\n",
      "Processed: 30.23%\n",
      "Processed: 32.56%\n",
      "Processed: 34.88%\n",
      "Processed: 37.21%\n",
      "Processed: 39.53%\n",
      "Processed: 41.86%\n",
      "Processed: 44.19%\n",
      "Processed: 46.51%\n",
      "Processed: 48.84%\n",
      "Processed: 51.16%\n",
      "Processed: 53.49%\n",
      "Processed: 55.81%\n",
      "Processed: 58.14%\n",
      "Processed: 60.47%\n",
      "Processed: 62.79%\n",
      "Processed: 65.12%\n",
      "Processed: 67.44%\n",
      "Processed: 69.77%\n",
      "Processed: 72.09%\n",
      "Processed: 74.42%\n",
      "Processed: 76.74%\n",
      "Processed: 79.07%\n",
      "Processed: 81.4%\n",
      "Processed: 83.72%\n",
      "Processed: 86.05%\n",
      "Processed: 88.37%\n",
      "Processed: 90.7%\n",
      "Processed: 93.02%\n",
      "Processed: 95.35%\n",
      "Processed: 97.67%\n"
     ]
    }
   ],
   "source": [
    "model = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-2-v2', max_length=512)\n",
    "\n",
    "ranked = {}\n",
    "\n",
    "# Rank the top 5000 passages for each query\n",
    "for i, (query_id, doc_ids) in enumerate(query_topK.items()):\n",
    "    print(f\"Processed: {round(i/len(query_topK)*100,2)}%\")\n",
    "    # print(query_id, doc_ids)\n",
    "    # print(es.get(index=INDEX_NAME, id=doc_ids[0])[\"_source\"][\"content\"])\n",
    "    # print(queriesToUse[query_id])\n",
    "\n",
    "    l = [(queriesToUse[int(query_id)], es.get(index=INDEX_NAME, id=doc_id)[\"_source\"][\"content\"]) for doc_id in doc_ids]\n",
    "    score = model.predict(l)\n",
    "    # print(score)\n",
    "    # print(len(score))\n",
    "    d = dict(zip(doc_ids, score))\n",
    "    ranked[query_id] = [k for k in sorted(d, key=d.get, reverse=True)]\n",
    "#     break\n",
    "# print(ranked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk indexing\n",
    "qrelspath = \"data/qrels/qrels.txt\"\n",
    "\n",
    "qrels = {}\n",
    "with open(qrelspath, encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        l = line.split(' ')\n",
    "\n",
    "        qid = l[0]\n",
    "        pid = l[2]\n",
    "        relevance = int(l[3])\n",
    "\n",
    "        if relevance > 0:\n",
    "            if qid in qrels.keys():\n",
    "                qrels[qid].add(pid)\n",
    "            else:\n",
    "                qrels[qid] = set([pid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_precision(system_ranking, ground_truth) -> float:\n",
    "    vals = []\n",
    "    over = 1\n",
    "    for rank_idx, rank in enumerate(system_ranking):\n",
    "        under = rank_idx+1\n",
    "        if rank in ground_truth:\n",
    "            vals.append(over / under)\n",
    "            over += 1\n",
    "    AP = sum(vals) / len(ground_truth)\n",
    "\n",
    "    return AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09030257145979574"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_ranking = query_topK[\"527433\"] # List\n",
    "system_truth = qrels[\"527433\"] # Set\n",
    "score = get_average_precision(system_ranking, system_truth)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reciprocal_rank(system_ranking, ground_truth) -> float:\n",
    "    AP = 0\n",
    "    for rank_idx, rank in enumerate(system_ranking):\n",
    "        under = rank_idx+1\n",
    "        if rank in ground_truth:\n",
    "            AP = 1 / under\n",
    "            break\n",
    "    \n",
    "    return AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_ranking = query_topK[\"527433\"] # List\n",
    "system_truth = qrels[\"527433\"] # Set\n",
    "score = get_reciprocal_rank(system_ranking, system_truth)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_eval_measure(system_rankings, ground_truths, eval_function: Callable) -> float:\n",
    "    results = []\n",
    "    for query in system_rankings:\n",
    "        if query in ground_truths.keys():\n",
    "            results.append(eval_function(system_rankings[query], ground_truths[query]))\n",
    "        else:\n",
    "            continue\n",
    "            # results.append(0) -> ?\n",
    "    return sum(results) / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = get_mean_eval_measure(query_topK, qrels, get_average_precision)\n",
    "mrr = get_mean_eval_measure(query_topK, qrels, get_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From BM25\n",
    "map = 0.32872575816078825\n",
    "\n",
    "mrr = 0.7265016684853105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3324887414761848\n",
      "0.7265135518853889\n"
     ]
    }
   ],
   "source": [
    "print(map)\n",
    "print(mrr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
