{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sigurd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "PUNCTUATIONS = string.punctuation\n",
    "from typing import Callable\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"passage_index\"\n",
    "INDEX_SETTINGS = {\n",
    "    'settings': {\n",
    "        'index': {\n",
    "            'number_of_shards': 1,\n",
    "            'number_of_replicas': 1,\n",
    "            'similarity': {\n",
    "                'default': {\n",
    "                    'type': 'BM25'\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"my_english_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"stopwords\": \"_english_\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"english_stop\",\n",
    "                        \"filter_english_minimal\"\n",
    "                    ]                \n",
    "                }\n",
    "            },\n",
    "            \"filter\" : {\n",
    "                \"filter_english_minimal\" : {\n",
    "                    \"type\": \"stemmer\",\n",
    "                    \"name\": \"minimal_english\"\n",
    "                },\n",
    "                \"english_stop\": {\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords\": \"_english_\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ElasticSearch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\elasticsearch\\connection\\base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'SIGURD-PC',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': 'YJyKScvqTBmLtOHBzhKNXQ',\n",
       " 'version': {'number': '7.17.6',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'zip',\n",
       "  'build_hash': 'f65e9d338dc1d07b642e14a27f338990148ee5b6',\n",
       "  'build_date': '2022-08-23T11:08:48.893373482Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.11.1',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch()\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create indexes for the passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigurd\\AppData\\Local\\Temp/ipykernel_11952/1683882437.py:1: DeprecationWarning: Using positional arguments for APIs is deprecated and will be disabled in 8.0.0. Instead use only keyword arguments for all APIs. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  if es.indices.exists(INDEX_NAME):\n",
      "C:\\Users\\Sigurd\\AppData\\Local\\Temp/ipykernel_11952/1683882437.py:4: DeprecationWarning: The 'body' parameter is deprecated for the 'create' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  es.indices.create(index=INDEX_NAME, body=INDEX_SETTINGS)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'passage_index'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if es.indices.exists(INDEX_NAME):\n",
    "    es.indices.delete(index=INDEX_NAME)\n",
    "\n",
    "es.indices.create(index=INDEX_NAME, body=INDEX_SETTINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add documents to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def tokenize(text, ps):\n",
    "    # Define text\n",
    "    return_text = text\n",
    "\n",
    "    # Remove specific punctuations\n",
    "    for punctuation in PUNCTUATIONS:\n",
    "        return_text = return_text.replace(punctuation, \" \")\n",
    "\n",
    "    # Get only the words, not the whitespace\n",
    "    words = [word for word in return_text.split(\" \") if word]\n",
    "\n",
    "    # Remove specific stopwords\n",
    "    words = [word for word in words if word not in STOPWORDS]\n",
    "\n",
    "    # Stemming\n",
    "    words = [ps.stem(word) for word in words]\n",
    "\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk indexing\n",
    "filename = \"data/collection/collection.tsv\"\n",
    "\n",
    "bulk_data = []\n",
    "bulk_size = 50000 # However many documents can be stored in memory\n",
    "with open(filename, encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        if len(bulk_data) > bulk_size:\n",
    "            es.bulk(index=INDEX_NAME, body=bulk_data, refresh=True, request_timeout=60)\n",
    "            bulk_data.clear()\n",
    "\n",
    "        l = line.split('\\t')\n",
    "        docid = int(l[0])\n",
    "        text = l[1].strip()\n",
    "\n",
    "        doc = {\"doc_id\": docid, \"content\": text} # tokenize(text, ps)}\n",
    "\n",
    "        bulk_data.append({\"index\": {\"_index\": INDEX_NAME, \"_id\": doc.pop(\"doc_id\")}})\n",
    "        bulk_data.append(doc)\n",
    "    \n",
    "    es.bulk(index=INDEX_NAME, body=bulk_data, refresh=True, request_timeout=60)\n",
    "    bulk_data.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '1',\n",
      " '_index': 'passage_index',\n",
      " '_primary_term': 1,\n",
      " '_seq_no': 1,\n",
      " '_source': {'content': 'The Manhattan Project and its atomic bomb helped '\n",
      "                        'bring an end to World War II. Its legacy of peaceful '\n",
      "                        'uses of atomic energy continues to have an impact on '\n",
      "                        'history and science.'},\n",
      " '_type': '_doc',\n",
      " '_version': 1,\n",
      " 'found': True}\n"
     ]
    }
   ],
   "source": [
    "doc = es.get(index=INDEX_NAME, id=1)\n",
    "pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"atomic bomb\"\n",
    "res = es.search(index=INDEX_NAME, q=query, _source=False, size=10, request_timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: '1478667'  Score: 25.89\n",
      "Doc ID: '2980807'  Score: 25.51\n",
      "Doc ID: '749030'  Score: 24.87\n",
      "Doc ID: '1653933'  Score: 24.69\n",
      "Doc ID: '1737931'  Score: 24.67\n",
      "Doc ID: '5169557'  Score: 24.57\n",
      "Doc ID: '2991343'  Score: 24.47\n",
      "Doc ID: '2840370'  Score: 24.47\n",
      "Doc ID: '6142042'  Score: 24.47\n",
      "Doc ID: '3386237'  Score: 24.43\n"
     ]
    }
   ],
   "source": [
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(\"Doc ID: %3r  Score: %5.2f\" % (hit[\"_id\"], hit[\"_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1478667',\n",
       " '2980807',\n",
       " '749030',\n",
       " '1653933',\n",
       " '1737931',\n",
       " '5169557',\n",
       " '2991343',\n",
       " '2840370',\n",
       " '6142042',\n",
       " '3386237']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_scores = [hit[\"_id\"] for hit in res[\"hits\"][\"hits\"]]\n",
    "top_k_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make QRELS evaluation-able\n",
    "- \"query_id\": [\"doc_id1\", \"doc_id2\"...] -> Relevant ones, ground truth, Set() in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk indexing\n",
    "qrelspath = \"data/qrels/qrels.txt\"\n",
    "\n",
    "qrels = {}\n",
    "with open(qrelspath, encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        l = line.split(' ')\n",
    "\n",
    "        qid = l[0]\n",
    "        pid = l[2]\n",
    "        relevance = int(l[3])\n",
    "\n",
    "        if relevance > 0:\n",
    "            if qid in qrels.keys():\n",
    "                qrels[qid].add(pid)\n",
    "            else:\n",
    "                qrels[qid] = set([pid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1720389',\n",
       " '1720395',\n",
       " '1729',\n",
       " '2046505',\n",
       " '3045565',\n",
       " '3045567',\n",
       " '3175481',\n",
       " '3175484',\n",
       " '527690',\n",
       " '527692',\n",
       " '527697',\n",
       " '6452949',\n",
       " '7122355',\n",
       " '7320614',\n",
       " '819168',\n",
       " '8412681',\n",
       " '8412682',\n",
       " '8412683',\n",
       " '8412684',\n",
       " '8412685'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels[\"19335\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qrels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19335'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_query_ids = list(qrels.keys())\n",
    "qrel_query_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_eval = pd.read_csv(\"data/queries/queries.eval.tsv\", sep='\\t', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786436\n",
      "what is prescribed to treat thyroid storm\n"
     ]
    }
   ],
   "source": [
    "queries_id = np.array(queries_eval[:, 0])\n",
    "queries = np.array(queries_eval[:, 1])\n",
    "print(queries_id[0])\n",
    "print(queries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_queries(queries, qrels):\n",
    "    relevant_queries = []\n",
    "    relevant_queries_id = []\n",
    "\n",
    "    for idx, query in enumerate(queries):\n",
    "        query_id = str(queries_id[idx])\n",
    "        if query_id in qrels:\n",
    "            relevant_queries.append(query)\n",
    "            relevant_queries_id.append(query_id)\n",
    "\n",
    "    return relevant_queries, relevant_queries_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527433\n",
      "types of dysarthria from cerebral palsy\n"
     ]
    }
   ],
   "source": [
    "# Keep only queries in the QRELS\n",
    "queries, queries_id = relevant_queries(queries, qrel_query_ids)\n",
    "print(queries_id[0])\n",
    "print(queries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_queries(queries, stemmer):\n",
    "#     tokenized_queries = []\n",
    "\n",
    "#     for query in queries:\n",
    "#         tokenized_queries.append(tokenize(query, stemmer))\n",
    "\n",
    "#     return tokenized_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the queries\n",
    "# queries = tokenize_queries(queries, ps)\n",
    "# print(queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non bulk query search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-bulk\n",
    "query_topK = {}\n",
    "for idx, query_id in enumerate(queries_id):\n",
    "    query = queries[idx]\n",
    "    res = es.search(index=INDEX_NAME, q=query, _source=False, size=1000, request_timeout=60)\n",
    "    top_k_scores = [hit[\"_id\"] for hit in res[\"hits\"][\"hits\"]]\n",
    "    query_topK[str(query_id)] = top_k_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "- MAP (Mean Average Precision)\n",
    "- MRR (Mean Reciprocal Recipient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_precision(system_ranking, ground_truth) -> float:\n",
    "    vals = []\n",
    "    over = 1\n",
    "    for rank_idx, rank in enumerate(system_ranking):\n",
    "        under = rank_idx+1\n",
    "        if rank in ground_truth:\n",
    "            vals.append(over / under)\n",
    "            over += 1\n",
    "    AP = sum(vals) / len(ground_truth)\n",
    "\n",
    "    return AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07231352770628346"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_ranking = query_topK[queries_id[0]] # List\n",
    "system_truth = qrels[queries_id[0]] # Set\n",
    "score = get_average_precision(system_ranking, system_truth)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reciprocal_rank(system_ranking, ground_truth) -> float:\n",
    "    AP = 0\n",
    "    for rank_idx, rank in enumerate(system_ranking):\n",
    "        under = rank_idx+1\n",
    "        if rank in ground_truth:\n",
    "            AP = 1 / under\n",
    "            break\n",
    "    \n",
    "    return AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_ranking = query_topK[queries_id[0]] # List\n",
    "system_truth = qrels[queries_id[0]] # Set\n",
    "score = get_reciprocal_rank(system_ranking, system_truth)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_eval_measure(system_rankings, ground_truths, eval_function: Callable) -> float:\n",
    "    results = []\n",
    "    for query in system_rankings:\n",
    "        if query in ground_truths.keys():\n",
    "            results.append(eval_function(system_rankings[query], ground_truths[query]))\n",
    "        else:\n",
    "            continue\n",
    "            # results.append(0) -> ?\n",
    "    return sum(results) / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = get_mean_eval_measure(query_topK, qrels, get_average_precision)\n",
    "mrr = get_mean_eval_measure(query_topK, qrels, get_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32872575816078825\n",
      "0.7265016684853105\n"
     ]
    }
   ],
   "source": [
    "print(map)\n",
    "print(mrr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afea23f61d6a821af1961b60809105e43be664e14901e921a7e345d902bc2549"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
